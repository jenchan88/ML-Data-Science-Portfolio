{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vbBIgaZN3dIt"},"outputs":[],"source":["import keras\n","import keras.applications\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","from PIL import Image\n","import os\n","import gc"]},{"cell_type":"markdown","metadata":{"id":"FTpVVjfW3dIw"},"source":["### Reading in Data"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rywuaxH76PFa","executionInfo":{"status":"ok","timestamp":1733451010208,"user_tz":480,"elapsed":23373,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"a9f71636-5a80-4f8b-d422-88488b174ebc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7jCo4tYk3dI2","colab":{"base_uri":"https://localhost:8080/","height":327},"executionInfo":{"status":"ok","timestamp":1733451073666,"user_tz":480,"elapsed":2199,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"013d5cd6-8adf-494d-8572-7a044c0536ed"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               Image  Old  More than 1 person  \\\n","0  Project3\\data403-project3\\Training_Data\\Alex\\A...    1                   0   \n","1  Project3\\data403-project3\\Training_Data\\Alex\\A...    1                   0   \n","2  Project3\\data403-project3\\Training_Data\\Alex\\A...    1                   0   \n","3  Project3\\data403-project3\\Training_Data\\Alex\\A...    0                   0   \n","4  Project3\\data403-project3\\Training_Data\\Alex\\A...    0                   0   \n","\n","   Saturation (Strong/Weak)  Nature  Blurry  Castle  Desert  Filter/Not  \\\n","0                         1       1       1       0       0           0   \n","1                         1       1       1       0       0           1   \n","2                         0       0       1       0       0           0   \n","3                         1       1       0       0       0           1   \n","4                         1       1       0       0       0           0   \n","\n","   Europe  Straight  Shadows (Strong/Weak)  \n","0       0         1                      0  \n","1       1         0                      1  \n","2       0         0                      0  \n","3       0         0                      0  \n","4       0         1                      1  "],"text/html":["\n","  <div id=\"df-072da317-5d2f-429f-aa87-fad106181a7a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image</th>\n","      <th>Old</th>\n","      <th>More than 1 person</th>\n","      <th>Saturation (Strong/Weak)</th>\n","      <th>Nature</th>\n","      <th>Blurry</th>\n","      <th>Castle</th>\n","      <th>Desert</th>\n","      <th>Filter/Not</th>\n","      <th>Europe</th>\n","      <th>Straight</th>\n","      <th>Shadows (Strong/Weak)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Project3\\data403-project3\\Training_Data\\Alex\\A...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Project3\\data403-project3\\Training_Data\\Alex\\A...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Project3\\data403-project3\\Training_Data\\Alex\\A...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Project3\\data403-project3\\Training_Data\\Alex\\A...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Project3\\data403-project3\\Training_Data\\Alex\\A...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-072da317-5d2f-429f-aa87-fad106181a7a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-072da317-5d2f-429f-aa87-fad106181a7a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-072da317-5d2f-429f-aa87-fad106181a7a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-936f4182-daab-4ab3-a5f8-66e2afc5cc3e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-936f4182-daab-4ab3-a5f8-66e2afc5cc3e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-936f4182-daab-4ab3-a5f8-66e2afc5cc3e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"manual_label","summary":"{\n  \"name\": \"manual_label\",\n  \"rows\": 529,\n  \"fields\": [\n    {\n      \"column\": \"Image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 529,\n        \"samples\": [\n          \"Project3\\\\data403-project3\\\\Training_Data\\\\Alex\\\\Alex-Image141.png\",\n          \"Project3\\\\data403-project3\\\\Training_Data\\\\Kelly\\\\Kelly-Image142.png\",\n          \"Project3\\\\data403-project3\\\\Training_Data\\\\Alex\\\\Alex-Image07.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Old\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"More than 1 person\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Saturation (Strong/Weak)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blurry\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Castle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Desert\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Filter/Not\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Europe\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Straight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shadows (Strong/Weak)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}],"source":["manual_label = pd.read_excel(\"/content/drive/MyDrive/Data403Materials/Data403Project3/Copy of Manual Labeling.xlsx\")\n","manual_label.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RsevzCUL3dI4"},"outputs":[],"source":["manual_label[\"Image\"] = manual_label[\"Image\"].str.split(\"\\\\\").str[-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZ8LsQ7u3dI5","outputId":"e52abba8-1991-4b8a-f434-51fc04e9213e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733451082329,"user_tz":480,"elapsed":388,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-095b37fda2ec>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  alex[\"Target\"] = 1\n","<ipython-input-5-095b37fda2ec>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  kelly[\"Target\"] = 0\n"]}],"source":["alex = manual_label[manual_label[\"Image\"].str.contains(\"Alex\")]\n","alex[\"Target\"] = 1\n","kelly = manual_label[manual_label[\"Image\"].str.contains(\"Kelly\")]\n","kelly[\"Target\"] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzcwvix23dI6","outputId":"044ee30a-8356-4506-8647-3624c6e217e0","colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"status":"ok","timestamp":1733451086656,"user_tz":480,"elapsed":1019,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Old  More than 1 person  Saturation (Strong/Weak)  Nature  Blurry  \\\n","0      1                   0                         1       1       1   \n","1      1                   0                         1       1       1   \n","2      1                   0                         0       0       1   \n","3      0                   0                         1       1       0   \n","4      0                   0                         1       1       0   \n","..   ...                 ...                       ...     ...     ...   \n","480    0                   0                         0       1       1   \n","481    0                   0                         1       1       0   \n","482    0                   1                         0       0       0   \n","483    1                   1                         0       0       1   \n","484    1                   1                         0       0       0   \n","\n","     Castle  Desert  Filter/Not  Europe  Straight  Shadows (Strong/Weak)  \\\n","0         0       0           0       0         1                      0   \n","1         0       0           1       1         0                      1   \n","2         0       0           0       0         0                      0   \n","3         0       0           1       0         0                      0   \n","4         0       0           0       0         1                      1   \n","..      ...     ...         ...     ...       ...                    ...   \n","480       0       0           0       0         0                      0   \n","481       0       0           0       0         1                      0   \n","482       0       0           0       0         0                      1   \n","483       0       0           0       0         0                      0   \n","484       0       0           0       0         0                      0   \n","\n","     Target  \n","0         1  \n","1         1  \n","2         1  \n","3         1  \n","4         1  \n","..      ...  \n","480       0  \n","481       0  \n","482       0  \n","483       0  \n","484       0  \n","\n","[485 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-8b423d6c-2cdf-4ace-9a08-0696a466ff67\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Old</th>\n","      <th>More than 1 person</th>\n","      <th>Saturation (Strong/Weak)</th>\n","      <th>Nature</th>\n","      <th>Blurry</th>\n","      <th>Castle</th>\n","      <th>Desert</th>\n","      <th>Filter/Not</th>\n","      <th>Europe</th>\n","      <th>Straight</th>\n","      <th>Shadows (Strong/Weak)</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>480</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>481</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>482</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>483</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>484</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>485 rows × 12 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b423d6c-2cdf-4ace-9a08-0696a466ff67')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8b423d6c-2cdf-4ace-9a08-0696a466ff67 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8b423d6c-2cdf-4ace-9a08-0696a466ff67');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0a8701f2-21ed-48cf-86fe-88b7d68b447b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a8701f2-21ed-48cf-86fe-88b7d68b447b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0a8701f2-21ed-48cf-86fe-88b7d68b447b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_5132f9db-616e-49fe-bbc1-ab3c1bdfa273\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('info_in_order')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_5132f9db-616e-49fe-bbc1-ab3c1bdfa273 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('info_in_order');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"info_in_order","summary":"{\n  \"name\": \"info_in_order\",\n  \"rows\": 485,\n  \"fields\": [\n    {\n      \"column\": \"Old\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"More than 1 person\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Saturation (Strong/Weak)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blurry\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Castle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Desert\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Filter/Not\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Europe\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Straight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shadows (Strong/Weak)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}],"source":["info_in_order = pd.concat([alex, kelly], axis = 0).iloc[:, 1:]\n","info_in_order"]},{"cell_type":"markdown","metadata":{"id":"n0r4PyNS3dI8"},"source":["### Resnet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GyvD0rjb3dI9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733454617688,"user_tz":480,"elapsed":311,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"74648c41-dc11-4b7b-d1af-768dd241c9c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 485 files belonging to 2 classes.\n"]}],"source":["set = keras.utils.image_dataset_from_directory(\n","    directory = \"/content/drive/MyDrive/Data403Materials/Data403Project3/trainingData\",\n","    image_size = (224, 224),\n","    shuffle = False,\n","    batch_size = 485\n",")"]},{"cell_type":"code","source":["import os\n","\n","# Check the files in the directory\n","directory = \"/content/drive/MyDrive/Data403Materials/Data403Project3/trainingData\"\n","files = os.listdir(directory)\n","files"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q0Wv6DNP0fkg","executionInfo":{"status":"ok","timestamp":1733452520091,"user_tz":480,"elapsed":401,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"de88e3b2-fb83-4c4b-dcee-0bb0ea22dad9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Alex', 'Kelly']"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["import os\n","\n","# Path to the training data directory\n","directory = \"/content/drive/MyDrive/Data403Materials/Data403Project3/trainingData\"\n","\n","# List all subdirectories (which should correspond to the classes, e.g., 'Alex', 'Kelly')\n","subdirectories = os.listdir(directory)\n","\n","# Initialize a dictionary to store the count of images for each class\n","class_image_counts = {}\n","\n","# Iterate through each subdirectory and count the image files\n","for subdirectory in subdirectories:\n","    # Full path of the subdirectory\n","    subdir_path = os.path.join(directory, subdirectory)\n","\n","    # Ensure it's a directory (not a file)\n","    if os.path.isdir(subdir_path):\n","        # Get all files in the subdirectory\n","        files_in_subdir = os.listdir(subdir_path)\n","\n","        # Count only the image files (optional: filter by file extension)\n","        image_files = [f for f in files_in_subdir if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif'))]\n","\n","        # Store the count of image files for this class\n","        class_image_counts[subdirectory] = len(image_files)\n","\n","# Print the counts for each class\n","print(class_image_counts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xe6REUON095x","executionInfo":{"status":"ok","timestamp":1733454606685,"user_tz":480,"elapsed":981,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"9412f628-1d0b-4e94-b5c8-ecb26feb19cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Alex': 256, 'Kelly': 229}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWmOntXF3dI_","outputId":"56d7006c-4c6c-4576-d671-c1bfe4d172d7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733452060699,"user_tz":480,"elapsed":302182,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n","Epoch 1/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 524ms/step - accuracy: 0.5062 - loss: 0.9697\n","Epoch 2/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6520 - loss: 0.6793\n","Epoch 3/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.6896 - loss: 0.5866\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7697 - loss: 0.4231\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.7944 - loss: 0.4320\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7739 - loss: 0.4271\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8300 - loss: 0.3723\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.8328 - loss: 0.3718\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.8960 - loss: 0.2801\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8756 - loss: 0.2937\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8008 - loss: 0.3824\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n","0.9583333333333334\n","Epoch 1/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 477ms/step - accuracy: 0.5068 - loss: 0.9211\n","Epoch 2/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.6867 - loss: 0.6354\n","Epoch 3/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.6853 - loss: 0.5592\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7422 - loss: 0.4888\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7618 - loss: 0.4556\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.8221 - loss: 0.4177\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7620 - loss: 0.4319\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8236 - loss: 0.3983\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8805 - loss: 0.3227\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8555 - loss: 0.3215\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 766ms/step - accuracy: 0.8101 - loss: 0.3566\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 774ms/step\n","0.979381443298969\n","Epoch 1/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 410ms/step - accuracy: 0.5303 - loss: 0.8528\n","Epoch 2/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.6674 - loss: 0.6007\n","Epoch 3/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.6703 - loss: 0.5496\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.7618 - loss: 0.4574\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.7651 - loss: 0.4721\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.7838 - loss: 0.3861\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7906 - loss: 0.4100\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8338 - loss: 0.3614\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8516 - loss: 0.3104\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8845 - loss: 0.2509\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 469ms/step - accuracy: 0.7853 - loss: 0.5272\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 553ms/step\n","0.9690721649484536\n","Epoch 1/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 401ms/step - accuracy: 0.5841 - loss: 0.7566\n","Epoch 2/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5866 - loss: 0.6656\n","Epoch 3/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.7022 - loss: 0.5783\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7193 - loss: 0.5555\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.7401 - loss: 0.5008\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.7643 - loss: 0.4203\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.7987 - loss: 0.4033\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.8271 - loss: 0.3570\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.8035 - loss: 0.3628\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8247 - loss: 0.3934\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 483ms/step - accuracy: 0.8569 - loss: 0.3591\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 305ms/step\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481ms/step\n","0.9484536082474226\n","Epoch 1/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 314ms/step - accuracy: 0.5557 - loss: 0.8827\n","Epoch 2/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.6953 - loss: 0.5676\n","Epoch 3/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.7299 - loss: 0.5295\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7923 - loss: 0.4642\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.7753 - loss: 0.4768\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.8094 - loss: 0.3975\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8290 - loss: 0.3546\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8290 - loss: 0.3644\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8720 - loss: 0.2961\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8520 - loss: 0.2888\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 470ms/step - accuracy: 0.8039 - loss: 0.4475\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step\n","0.9278350515463918\n","[0.8125, 0.8144329786300659, 0.7835051417350769, 0.8350515365600586, 0.8041236996650696]\n"]}],"source":["accuracy_list = []\n","accuracy_list_with_manual = []\n","def cross_val(num_folds = 5):\n","    total_indices = np.array(list(range(0, 485)))\n","    np.random.shuffle(total_indices)\n","    for i in range(0, num_folds):\n","        # print(i * (total_indices.size-1) // num_folds, (i + 1) * (total_indices.size-1) // num_folds)\n","        test_indices = total_indices[i * (total_indices.size-1) // num_folds : (i + 1) * (total_indices.size-1) // num_folds]\n","        train_indices = total_indices[np.isin(total_indices, test_indices, invert = True)] # for some reason setdiff1d sorts in order... facepalm\n","\n","        train_x = set.as_numpy_iterator().next()[0][train_indices]\n","        train_y = set.as_numpy_iterator().next()[1][train_indices]\n","        test_x = set.as_numpy_iterator().next()[0][test_indices]\n","        test_y = set.as_numpy_iterator().next()[1][test_indices]\n","\n","        train = tf.data.Dataset.from_tensor_slices((tf.constant(train_x), tf.constant(train_y))).batch(32)\n","        test = tf.data.Dataset.from_tensor_slices((tf.constant(test_x), tf.constant(test_y))).batch(32)\n","\n","        model = keras.applications.ResNet50(\n","            include_top = False,\n","            input_shape = (224, 224, 3)\n","        )\n","        model.trainable = False\n","        final_model = keras.models.Sequential()\n","        final_model.add(model)\n","        final_model.add(keras.layers.GlobalAveragePooling2D())\n","        final_model.add(keras.layers.Dense(64, activation = \"relu\"))\n","        final_model.add(keras.layers.Dropout(0.5))\n","        final_model.add(keras.layers.Dense(16, activation = \"relu\"))\n","        final_model.add(keras.layers.Dropout(0.3))\n","        final_model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n","\n","        final_model.compile(optimizer = \"adam\",\n","                    loss = \"binary_crossentropy\",\n","                    metrics = [\"accuracy\"])\n","        final_model.fit(train, epochs = 10)\n","\n","        accuracy_list.append(final_model.evaluate(test)[1])\n","\n","        # combine both results and use log reg\n","        model_predictions = final_model.predict(train_x)\n","        train_image = info_in_order.iloc[train_indices]\n","        actual_y = train_image.iloc[:, -1]\n","        intermediate = train_image.iloc[:, :-1]\n","        actual_x = pd.concat([intermediate.reset_index(drop = True), pd.DataFrame(model_predictions, columns = [\"prediction\"])], axis = 1)\n","\n","        log_reg = LogisticRegression()\n","        log_reg.fit(actual_x, actual_y)\n","\n","        model_predictions = final_model.predict(test_x)\n","        test_image = info_in_order.iloc[test_indices]\n","        actual_y = test_image.iloc[:, -1]\n","        intermediate = test_image.iloc[:, :-1]\n","        actual_x = pd.concat([intermediate.reset_index(drop = True), pd.DataFrame(model_predictions, columns = [\"prediction\"])], axis = 1)\n","        accuracy_list_with_manual.append(accuracy_score(actual_y, log_reg.predict(actual_x)))\n","        print(accuracy_score(actual_y, log_reg.predict(actual_x)))\n","\n","\n","\n","\n","cross_val(num_folds = 5)\n","print(accuracy_list)\n","\n","np.array(accuracy_list).mean()\n","np.array(accuracy_list_with_manual).mean()\n","\n","set = keras.utils.image_dataset_from_directory(\n","    directory = \"/content/drive/MyDrive/Data403Materials/Data403Project3/trainingData\",\n","    image_size = (224, 224),\n","    shuffle = True,\n","    batch_size = 32\n",")\n","model = keras.applications.ResNet50(\n","    include_top = False,\n","    input_shape = (224, 224, 3)\n",")\n","model.trainable = False\n","final_model = keras.models.Sequential()\n","final_model.add(model)\n","final_model.add(keras.layers.GlobalAveragePooling2D())\n","final_model.add(keras.layers.Dense(64, activation = \"relu\"))\n","final_model.add(keras.layers.Dropout(0.5))\n","final_model.add(keras.layers.Dense(16, activation = \"relu\"))\n","final_model.add(keras.layers.Dropout(0.3))\n","final_model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n","\n","final_model.compile(optimizer = \"adam\",\n","            loss = \"binary_crossentropy\",\n","            metrics = [\"accuracy\"])\n","final_model.fit(set, epochs = 10)\n","predictions = final_model.predict(set)\n","\n","\n","input_1 = pd.concat([info_in_order.iloc[:, :-1].reset_index(drop = True), pd.DataFrame(predictions, columns = [\"prediction\"])], axis = 1)\n","\n","final_log_reg = LogisticRegression()\n","final_log_reg.fit(input_1, info_in_order.iloc[:, -1])\n","\n","test_set_01 = manual_label[manual_label[\"Image\"].str.contains(\"TestSetImage\")]\n","test_set_01_images = keras.utils.image_dataset_from_directory(\n","    directory = \"/content/drive/MyDrive/Data403Materials/Data403Project3/testData/TestSet01\",\n","    image_size = (224, 224),\n","    labels = None,\n","    shuffle = False,\n","    batch_size = 24\n",")\n","model_predict_test = final_model.predict(test_set_01_images)\n","final_output = pd.concat([test_set_01.reset_index(drop = True), pd.DataFrame(model_predict_test, columns = [\"prediction\"])], axis = 1)\n","final_log_reg.predict(final_output.iloc[:, 1:])"]},{"cell_type":"markdown","source":["CNN"],"metadata":{"id":"kJmsLvyYFIfy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"63_udWzo3dJA","outputId":"d722fb8e-46ba-4f7c-b96c-7a33131bc6ad","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733452114652,"user_tz":480,"elapsed":346,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8099226713180542"]},"metadata":{},"execution_count":12}],"source":["np.array(accuracy_list).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CqLYCHY33dJB","outputId":"5687c99d-fb90-4002-fdbc-0c53465cb4c0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733454912710,"user_tz":480,"elapsed":401,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9566151202749141"]},"metadata":{},"execution_count":28}],"source":["np.array(accuracy_list_with_manual).mean()"]},{"cell_type":"markdown","metadata":{"id":"iOXA9kVf3dJC"},"source":["### Performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rmyYw9n83dJD","outputId":"940d0e62-c8da-4914-ce2f-ff330e2ed4b7","colab":{"base_uri":"https://localhost:8080/","height":461},"executionInfo":{"status":"ok","timestamp":1733454979660,"user_tz":480,"elapsed":65417,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 485 files belonging to 2 classes.\n","Epoch 1/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 428ms/step - accuracy: 0.5345 - loss: 0.8271\n","Epoch 2/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 176ms/step - accuracy: 0.6247 - loss: 0.6601\n","Epoch 3/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 0.7276 - loss: 0.5180\n","Epoch 4/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 0.7558 - loss: 0.4662\n","Epoch 5/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - accuracy: 0.7755 - loss: 0.4602\n","Epoch 6/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - accuracy: 0.7904 - loss: 0.4018\n","Epoch 7/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.8105 - loss: 0.3759\n","Epoch 8/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.8516 - loss: 0.3117\n","Epoch 9/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 186ms/step - accuracy: 0.8349 - loss: 0.3218\n","Epoch 10/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 184ms/step - accuracy: 0.8809 - loss: 0.2723\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 332ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["LogisticRegression()"],"text/html":["<style>#sk-container-id-2 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-2 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-2 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-2 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-2 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-2 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-2 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-2 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-2 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-2 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-2 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-2 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-2 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-2 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-2 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-2 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-2 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"]},"metadata":{},"execution_count":29}],"source":["set = keras.utils.image_dataset_from_directory(\n","    directory = \"/content/drive/MyDrive/Data403Materials/Data403Project3/trainingData\",\n","    image_size = (224, 224),\n","    shuffle = True,\n","    batch_size = 32\n",")\n","model = keras.applications.ResNet50(\n","    include_top = False,\n","    input_shape = (224, 224, 3)\n",")\n","model.trainable = False\n","final_model = keras.models.Sequential()\n","final_model.add(model)\n","final_model.add(keras.layers.GlobalAveragePooling2D())\n","final_model.add(keras.layers.Dense(64, activation = \"relu\"))\n","final_model.add(keras.layers.Dropout(0.5))\n","final_model.add(keras.layers.Dense(16, activation = \"relu\"))\n","final_model.add(keras.layers.Dropout(0.3))\n","final_model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n","\n","final_model.compile(optimizer = \"adam\",\n","            loss = \"binary_crossentropy\",\n","            metrics = [\"accuracy\"])\n","final_model.fit(set, epochs = 10)\n","predictions = final_model.predict(set)\n","\n","\n","input_1 = pd.concat([info_in_order.iloc[:, :-1].reset_index(drop = True), pd.DataFrame(predictions, columns = [\"prediction\"])], axis = 1)\n","\n","final_log_reg = LogisticRegression()\n","final_log_reg.fit(input_1, info_in_order.iloc[:, -1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1RUF15v3dJD","outputId":"6b2b8f9a-c861-4c81-a166-690d5cd0b64d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733455007871,"user_tz":480,"elapsed":11178,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20 files.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0])"]},"metadata":{},"execution_count":30}],"source":["test_set_01 = manual_label[manual_label[\"Image\"].str.contains(\"TestSetImage\")]\n","test_set_01_images = keras.utils.image_dataset_from_directory(\n","    directory = \"/content/drive/MyDrive/Data403Materials/Data403Project3/testData/TestSet01\",\n","    image_size = (224, 224),\n","    labels = None,\n","    shuffle = False,\n","    batch_size = 24\n",")\n","model_predict_test = final_model.predict(test_set_01_images)\n","final_output = pd.concat([test_set_01.reset_index(drop = True), pd.DataFrame(model_predict_test, columns = [\"prediction\"])], axis = 1)\n","final_log_reg.predict(final_output.iloc[:, 1:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0g-zfy6W3dJE","outputId":"4a8a56d4-cc47-4397-9a8e-74962aaa7fb5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733455035950,"user_tz":480,"elapsed":314,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0]])"]},"metadata":{},"execution_count":31}],"source":["np.where(final_model.predict(test_set_01_images) > 0.5, 1, 0).reshape(-1, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RIcDo7yx3dJE","outputId":"6800bb60-3759-4d50-8a39-6883b47825a6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733455087981,"user_tz":480,"elapsed":9698,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 24 files.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.96620829, 0.03379171],\n","       [0.38245092, 0.61754908],\n","       [0.03626881, 0.96373119],\n","       [0.97065997, 0.02934003],\n","       [0.13689565, 0.86310435],\n","       [0.96901933, 0.03098067],\n","       [0.83305645, 0.16694355],\n","       [0.83700131, 0.16299869],\n","       [0.58728945, 0.41271055],\n","       [0.8361609 , 0.1638391 ],\n","       [0.96912091, 0.03087909],\n","       [0.98287134, 0.01712866],\n","       [0.96939904, 0.03060096],\n","       [0.97088924, 0.02911076],\n","       [0.96951077, 0.03048923],\n","       [0.94717635, 0.05282365],\n","       [0.97113409, 0.02886591],\n","       [0.36218169, 0.63781831],\n","       [0.97059287, 0.02940713],\n","       [0.37235845, 0.62764155],\n","       [0.96977775, 0.03022225],\n","       [0.91106782, 0.08893218],\n","       [0.98962042, 0.01037958],\n","       [0.83470594, 0.16529406]])"]},"metadata":{},"execution_count":33}],"source":["test_set_02 = manual_label[manual_label[\"Image\"].str.contains(\"TestSet02\")]\n","test_set_02_images = keras.utils.image_dataset_from_directory(\n","    directory = \"/content/drive/MyDrive/Data403Materials/Data403Project3/testData/TestSet02\",\n","    image_size = (224, 224),\n","    labels = None,\n","    shuffle = False,\n","    batch_size = 24\n",")\n","model_predict_test = final_model.predict(test_set_02_images)\n","final_output = pd.concat([test_set_02.reset_index(drop = True), pd.DataFrame(model_predict_test, columns = [\"prediction\"])], axis = 1)\n","final_log_reg.predict_proba(final_output.iloc[:, 1:])"]},{"cell_type":"markdown","source":["VGG16 (Type of CNN Model)\n"],"metadata":{"id":"6F9iVv9Gob2V"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","import numpy as np\n","\n","# Load the image dataset from directory (ensure the folder structure is as explained)\n","image_data = tf.keras.utils.image_dataset_from_directory(\n","    directory=\"/content/drive/MyDrive/Data403Materials/Data403Project3/trainingData\",\n","    image_size=(224, 224),  # Resize to 224x224\n","    shuffle=True,  # Shuffle the data\n","    batch_size=32  # Set batch size\n",")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ib-0Wpbxoflc","executionInfo":{"status":"ok","timestamp":1733456559110,"user_tz":480,"elapsed":319,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"3e40da8e-7a86-4b55-f45d-89864f6922d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 485 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["# Load the VGG16 model with pre-trained weights, excluding the top (classification) layers\n","vgg_model = keras.applications.VGG16(\n","    include_top=False,\n","    input_shape=(224, 224, 3)\n",")\n","vgg_model.trainable = False  # Freeze the layers in VGG16 (we only use it as a feature extractor)\n","\n","# Create a custom model using VGG16 as a base\n","final_model_vgg = keras.Sequential()\n","final_model_vgg.add(vgg_model)  # Add the VGG16 model\n","final_model_vgg.add(keras.layers.GlobalAveragePooling2D())  # Pool the features\n","final_model_vgg.add(keras.layers.Dense(64, activation=\"relu\"))  # Add custom dense layers\n","final_model_vgg.add(keras.layers.Dropout(0.5))  # Dropout for regularization\n","final_model_vgg.add(keras.layers.Dense(16, activation=\"relu\"))\n","final_model_vgg.add(keras.layers.Dropout(0.3))  # Dropout for regularization\n","final_model_vgg.add(keras.layers.Dense(1, activation=\"sigmoid\"))  # Output layer for binary classification\n","\n","# Compile the model\n","final_model_vgg.compile(\n","    optimizer=\"adam\",\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Train the model on the image dataset\n","final_model_vgg.fit(image_data, epochs=10)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fkp5YCrMo2Sb","executionInfo":{"status":"ok","timestamp":1733455212425,"user_tz":480,"elapsed":60318,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"d6cc3e78-9af3-4604-de01-ef1271aba403"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 551ms/step - accuracy: 0.5127 - loss: 2.3986\n","Epoch 2/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 298ms/step - accuracy: 0.6040 - loss: 0.9053\n","Epoch 3/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 197ms/step - accuracy: 0.5727 - loss: 0.8159\n","Epoch 4/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.7060 - loss: 0.6647\n","Epoch 5/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 254ms/step - accuracy: 0.6921 - loss: 0.6532\n","Epoch 6/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - accuracy: 0.6862 - loss: 0.5985\n","Epoch 7/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 0.6930 - loss: 0.5841\n","Epoch 8/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 255ms/step - accuracy: 0.7113 - loss: 0.5756\n","Epoch 9/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 234ms/step - accuracy: 0.7027 - loss: 0.5550\n","Epoch 10/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 196ms/step - accuracy: 0.7567 - loss: 0.4734\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7f4a34f27b20>"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# Predict using the trained model\n","image_predictions_vgg = final_model_vgg.predict(image_data)\n","\n","# Now, load the manual features (assuming you have the 'info_in_order' DataFrame)\n","# Merge the image predictions with the manual features (info_in_order should already have the manual features)\n","input_data_vgg = pd.concat([info_in_order.iloc[:, :-1].reset_index(drop=True), pd.DataFrame(image_predictions_vgg, columns=[\"prediction\"])], axis=1)\n","\n","# Train a Logistic Regression model using both the image features and manual features\n","log_reg_model_vgg = LogisticRegression()\n","log_reg_model_vgg.fit(input_data_vgg, info_in_order.iloc[:, -1])  # info_in_order.iloc[:, -1] is the target (labels)\n","\n","# Predict with Logistic Regression on the combined data\n","log_reg_predictions_vgg = log_reg_model_vgg.predict(input_data_vgg)\n","\n","# Evaluate the Logistic Regression model (you can use accuracy score or any other metric)\n","accuracy_vgg = accuracy_score(info_in_order.iloc[:, -1], log_reg_predictions_vgg)\n","print(f\"Logistic Regression Accuracy using VGG16: {accuracy_vgg}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Sdqi6q5vjRa","executionInfo":{"status":"ok","timestamp":1733455243613,"user_tz":480,"elapsed":4437,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"3462a787-db4e-47db-f24a-810929513c9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 20 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4a34d4aef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 215ms/step\n","Logistic Regression Accuracy using VGG16: 0.9587628865979382\n"]}]},{"cell_type":"markdown","source":["MobileNetV2 Model"],"metadata":{"id":"jrbNeYXND1c1"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","import numpy as np\n","\n","# Load the image dataset from directory (ensure the folder structure is as explained)\n","image_data = tf.keras.utils.image_dataset_from_directory(\n","    directory=\"/content/drive/MyDrive/Data403Materials/Data403Project3/trainingData\",\n","    image_size=(224, 224),  # Resize to 224x224\n","    shuffle=True,  # Shuffle the data\n","    batch_size=32  # Set batch size\n",")\n","\n","set = keras.utils.image_dataset_from_directory(\n","    directory = \"/content/drive/MyDrive/Data403Materials/Data403Project3/trainingData\",\n","    image_size = (224, 224),\n","    shuffle = False,\n","    batch_size = 485\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nznT3N8mIP8n","executionInfo":{"status":"ok","timestamp":1733457793133,"user_tz":480,"elapsed":593,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"12b0c2e3-1bd4-4f86-c32e-3424faec4400"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 485 files belonging to 2 classes.\n","Found 485 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","\n","# Initialize accuracy lists\n","accuracy_list = []\n","accuracy_list_with_manual = []\n","\n","def cross_val(num_folds=5):\n","    total_indices = np.array(list(range(0, 485)))\n","    np.random.shuffle(total_indices)\n","    for i in range(0, num_folds):\n","        test_indices = total_indices[i * (total_indices.size - 1) // num_folds : (i + 1) * (total_indices.size - 1) // num_folds]\n","        train_indices = total_indices[np.isin(total_indices, test_indices, invert=True)]\n","\n","        train_x = set.as_numpy_iterator().next()[0][train_indices]\n","        train_y = set.as_numpy_iterator().next()[1][train_indices]\n","        test_x = set.as_numpy_iterator().next()[0][test_indices]\n","        test_y = set.as_numpy_iterator().next()[1][test_indices]\n","\n","        train = tf.data.Dataset.from_tensor_slices((tf.constant(train_x), tf.constant(train_y))).batch(32)\n","        test = tf.data.Dataset.from_tensor_slices((tf.constant(test_x), tf.constant(test_y))).batch(32)\n","\n","        # Use MobileNetV2 instead of ResNet50\n","        base_model = keras.applications.MobileNetV2(\n","            include_top=False,\n","            input_shape=(224, 224, 3)\n","        )\n","        base_model.trainable = False\n","\n","        # Build the final model\n","        final_model = keras.models.Sequential()\n","        final_model.add(base_model)\n","        final_model.add(keras.layers.GlobalAveragePooling2D())\n","        final_model.add(keras.layers.Dense(64, activation=\"relu\"))\n","        final_model.add(keras.layers.Dropout(0.5))\n","        final_model.add(keras.layers.Dense(16, activation=\"relu\"))\n","        final_model.add(keras.layers.Dropout(0.3))\n","        final_model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n","\n","        final_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","        final_model.fit(train, epochs=10)\n","\n","        # Evaluate the model\n","        accuracy_list.append(final_model.evaluate(test)[1])\n","\n","        # Combine predictions with manual features for logistic regression\n","        model_predictions = final_model.predict(train_x)\n","        train_image = info_in_order.iloc[train_indices]\n","        actual_y = train_image.iloc[:, -1]\n","        intermediate = train_image.iloc[:, :-1]\n","        actual_x = pd.concat([intermediate.reset_index(drop=True), pd.DataFrame(model_predictions, columns=[\"prediction\"])], axis=1)\n","\n","        log_reg = LogisticRegression()\n","        log_reg.fit(actual_x, actual_y)\n","\n","        model_predictions = final_model.predict(test_x)\n","        test_image = info_in_order.iloc[test_indices]\n","        actual_y = test_image.iloc[:, -1]\n","        intermediate = test_image.iloc[:, :-1]\n","        actual_x = pd.concat([intermediate.reset_index(drop=True), pd.DataFrame(model_predictions, columns=[\"prediction\"])], axis=1)\n","        accuracy_list_with_manual.append(accuracy_score(actual_y, log_reg.predict(actual_x)))\n","        print(accuracy_score(actual_y, log_reg.predict(actual_x)))\n","\n","# Run cross-validation\n","cross_val(num_folds=5)\n","print(accuracy_list)\n","print(\"Mean Accuracy (Base Model):\", np.array(accuracy_list).mean())\n","print(\"Mean Accuracy (Combined Model):\", np.array(accuracy_list_with_manual).mean())\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vfaKkfGcIBQI","executionInfo":{"status":"ok","timestamp":1733458055238,"user_tz":480,"elapsed":256263,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"9164c98c-c73d-434c-8de4-1d24ae2adb54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","Epoch 1/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 351ms/step - accuracy: 0.5372 - loss: 0.8655\n","Epoch 2/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5323 - loss: 0.7266\n","Epoch 3/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5837 - loss: 0.6932\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5094 - loss: 0.7195\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5480 - loss: 0.6818\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5483 - loss: 0.6855\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6360 - loss: 0.6429\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6327 - loss: 0.6516\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6785 - loss: 0.6018\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6313 - loss: 0.6367\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6797 - loss: 0.6133\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 236ms/step\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","0.9583333333333334\n","Epoch 1/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 360ms/step - accuracy: 0.4536 - loss: 0.8045\n","Epoch 2/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5294 - loss: 0.7401\n","Epoch 3/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5559 - loss: 0.7198\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5632 - loss: 0.6907\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5312 - loss: 0.7062\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6338 - loss: 0.6385\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5907 - loss: 0.6627\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6287 - loss: 0.6414\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5985 - loss: 0.6231\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6261 - loss: 0.6161\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 795ms/step - accuracy: 0.7447 - loss: 0.5916\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 238ms/step\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 584ms/step\n","0.9381443298969072\n","Epoch 1/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - accuracy: 0.5321 - loss: 0.7660\n","Epoch 2/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5563 - loss: 0.7087\n","Epoch 3/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5235 - loss: 0.6912\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5664 - loss: 0.6774\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5411 - loss: 0.6981\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5467 - loss: 0.6747\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5806 - loss: 0.6703\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5152 - loss: 0.7021\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5834 - loss: 0.6640\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5912 - loss: 0.6438\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 411ms/step - accuracy: 0.6380 - loss: 0.6710\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 220ms/step\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393ms/step\n","0.9690721649484536\n","Epoch 1/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 243ms/step - accuracy: 0.4985 - loss: 0.8170\n","Epoch 2/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.5291 - loss: 0.7270\n","Epoch 3/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5380 - loss: 0.7207\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5635 - loss: 0.6763\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5825 - loss: 0.6786\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5422 - loss: 0.6736\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5924 - loss: 0.6670\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6449 - loss: 0.6284\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6003 - loss: 0.6347\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6430 - loss: 0.6186\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 417ms/step - accuracy: 0.7200 - loss: 0.6129\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 292ms/step\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step\n","0.9381443298969072\n","Epoch 1/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 297ms/step - accuracy: 0.4647 - loss: 0.7798\n","Epoch 2/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5614 - loss: 0.6893\n","Epoch 3/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6401 - loss: 0.6625\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6006 - loss: 0.6717\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6169 - loss: 0.6383\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6557 - loss: 0.6198\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6462 - loss: 0.6559\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7121 - loss: 0.5739\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7005 - loss: 0.5702\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6810 - loss: 0.5659\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 582ms/step - accuracy: 0.6598 - loss: 0.5889\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394ms/step\n","0.9896907216494846\n","[0.65625, 0.7731958627700806, 0.6185566782951355, 0.6907216310501099, 0.6494845151901245]\n","Mean Accuracy (Base Model): 0.6776417374610901\n","Mean Accuracy (Combined Model): 0.9586769759450172\n"]}]},{"cell_type":"code","source":["# Training the final model on the entire dataset\n","set = keras.utils.image_dataset_from_directory(\n","    directory=\"/content/drive/MyDrive/Data403Materials/Data403Project3/trainingData\",\n","    image_size=(224, 224),\n","    shuffle=True,\n","    batch_size=32\n",")\n","\n","base_model = keras.applications.MobileNetV2(\n","    include_top=False,\n","    input_shape=(224, 224, 3)\n",")\n","base_model.trainable = False\n","\n","final_model = keras.models.Sequential()\n","final_model.add(base_model)\n","final_model.add(keras.layers.GlobalAveragePooling2D())\n","final_model.add(keras.layers.Dense(64, activation=\"relu\"))\n","final_model.add(keras.layers.Dropout(0.5))\n","final_model.add(keras.layers.Dense(16, activation=\"relu\"))\n","final_model.add(keras.layers.Dropout(0.3))\n","final_model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n","\n","final_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","final_model.fit(set, epochs=10)\n","\n","# Predict using the final model\n","predictions = final_model.predict(set)\n","\n","input_1 = pd.concat([info_in_order.iloc[:, :-1].reset_index(drop=True), pd.DataFrame(predictions, columns=[\"prediction\"])], axis=1)\n","final_log_reg = LogisticRegression()\n","final_log_reg.fit(input_1, info_in_order.iloc[:, -1])\n","\n","# Predict on TestSet01\n","test_set_01 = manual_label[manual_label[\"Image\"].str.contains(\"TestSetImage\")]\n","test_set_01_images = keras.utils.image_dataset_from_directory(\n","    directory=\"/content/drive/MyDrive/Data403Materials/Data403Project3/testData/TestSet01\",\n","    image_size=(224, 224),\n","    labels=None,\n","    shuffle=False,\n","    batch_size=24\n",")\n","model_predict_test = final_model.predict(test_set_01_images)\n","final_output = pd.concat([test_set_01.reset_index(drop=True), pd.DataFrame(model_predict_test, columns=[\"prediction\"])], axis=1)\n","final_predictions = final_log_reg.predict(final_output.iloc[:, 1:])\n","print(\"Final TestSet01 Predictions:\", final_predictions)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iayiGbe1IV_t","executionInfo":{"status":"ok","timestamp":1733458198371,"user_tz":480,"elapsed":69142,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"c74564db-3376-4340-c7a6-e1ef31293fb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 485 files belonging to 2 classes.\n","Epoch 1/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 296ms/step - accuracy: 0.4739 - loss: 0.9053\n","Epoch 2/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.5073 - loss: 0.7186\n","Epoch 3/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.5428 - loss: 0.6874\n","Epoch 4/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.5767 - loss: 0.6728\n","Epoch 5/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.5411 - loss: 0.6913\n","Epoch 6/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.5520 - loss: 0.6882\n","Epoch 7/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 177ms/step - accuracy: 0.6507 - loss: 0.6339\n","Epoch 8/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.6226 - loss: 0.6414\n","Epoch 9/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.6550 - loss: 0.6238\n","Epoch 10/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.6877 - loss: 0.6079\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 351ms/step\n","Found 20 files.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n","Final TestSet01 Predictions: [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0]\n"]}]},{"cell_type":"code","source":["np.where(final_model.predict(test_set_01_images) > 0.5, 1, 0).reshape(-1, 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwWMHxRxKsD0","executionInfo":{"status":"ok","timestamp":1733459309887,"user_tz":480,"elapsed":768,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"7be16128-8a34-40d6-f145-980105a0032c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1]])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["test_set_02 = manual_label[manual_label[\"Image\"].str.contains(\"TestSet02\")]\n","test_set_02_images = keras.utils.image_dataset_from_directory(\n","    directory = \"/content/drive/MyDrive/Data403Materials/Data403Project3/testData/TestSet02\",\n","    image_size = (224, 224),\n","    labels = None,\n","    shuffle = False,\n","    batch_size = 24\n",")\n","model_predict_test = final_model.predict(test_set_02_images)\n","final_output = pd.concat([test_set_02.reset_index(drop = True), pd.DataFrame(model_predict_test, columns = [\"prediction\"])], axis = 1)\n","final_log_reg.predict_proba(final_output.iloc[:, 1:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W7y5fPeBOf2r","executionInfo":{"status":"ok","timestamp":1733459336110,"user_tz":480,"elapsed":5915,"user":{"displayName":"Jenna Chan","userId":"16991838874527705980"}},"outputId":"14362698-7838-489a-d6c1-4e6d4585432a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 24 files.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.96708723, 0.03291277],\n","       [0.39172731, 0.60827269],\n","       [0.0347275 , 0.9652725 ],\n","       [0.97048127, 0.02951873],\n","       [0.13435028, 0.86564972],\n","       [0.96941146, 0.03058854],\n","       [0.83329848, 0.16670152],\n","       [0.83039235, 0.16960765],\n","       [0.58594653, 0.41405347],\n","       [0.82374975, 0.17625025],\n","       [0.96888419, 0.03111581],\n","       [0.98279362, 0.01720638],\n","       [0.96858121, 0.03141879],\n","       [0.9705966 , 0.0294034 ],\n","       [0.9680986 , 0.0319014 ],\n","       [0.94711149, 0.05288851],\n","       [0.97066519, 0.02933481],\n","       [0.37318534, 0.62681466],\n","       [0.97035043, 0.02964957],\n","       [0.36812186, 0.63187814],\n","       [0.96895808, 0.03104192],\n","       [0.91142666, 0.08857334],\n","       [0.98923148, 0.01076852],\n","       [0.83432813, 0.16567187]])"]},"metadata":{},"execution_count":45}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}